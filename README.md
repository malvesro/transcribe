# ğŸ™ï¸ Whisper Transcriber com Docker

<p align="center">
  <a href="https://github.com/malvesro/transcribe">
    <img src="https://img.shields.io/badge/GitHub-malvesro%2Ftranscribe-blue?style=for-the-badge&logo=github" alt="RepositÃ³rio GitHub">
  </a>
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python" alt="Python Version">
  <img src="https://img.shields.io/badge/Docker-Compatible-blue?style=for-the-badge&logo=docker" alt="Docker Compatible">
  <img src="https://img.shields.io/badge/GPU-NVIDIA%20CUDA-green?style=for-the-badge&logo=nvidia" alt="NVIDIA CUDA Compatible">
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="MIT License">
</p>

## ğŸ“„ SumÃ¡rio

* [VisÃ£o Geral](#-visÃ£o-geral)
  
* [Funcionalidades](#-funcionalidades)
  
* [PrÃ©-requisitos](#-prÃ©-requisitos)
  
* [Como ComeÃ§ar](#-como-comeÃ§ar)
  

Â  Â  * [Estrutura do Projeto](#estrutura-do-projeto)

Â  Â  * [Executando o Setup Inicial](#executando-o-setup-inicial)

* [Uso da Ferramenta](#-uso-da-ferramenta)

Â  Â  * [Exemplos de TranscriÃ§Ã£o](#exemplos-de-transcriÃ§Ã£o)

Â  Â  * [Entendendo os Aliases](#entendendo-os-aliases)

Â  Â  * [Uso AvanÃ§ado: Trocando o Modelo](#uso-avanÃ§ado-trocando-o-modelo)

* [Detalhes TÃ©cnicos](#-detalhes-tÃ©cnicos)

Â  Â  * [`Dockerfile.txt`](#dockertxt)

Â  Â  * [`transcribe.py`](#transcribepy)

Â  Â  * [`setup.sh`](#setupsh)

* [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
  
* [LicenÃ§a](#-licenÃ§a)
  
* [Contato](#-contato)
  

* * *

## ğŸ’¡ VisÃ£o Geral

Este projeto oferece uma soluÃ§Ã£o simplificada e eficiente para transcrever Ã¡udios de arquivos de vÃ­deo em texto utilizando o poder da inteligÃªncia artificial do [OpenAI Whisper](https://openai.com/research/whisper). Todo o ambiente Ã© empacotado em um contÃªiner Docker, o que garante isolamento, portabilidade e uma configuraÃ§Ã£o descomplicada, especialmente para usuÃ¡rios que desejam aproveitar a aceleraÃ§Ã£o de hardware (GPU NVIDIA).

Com um Ãºnico script de setup, vocÃª terÃ¡ o ambiente preparado e atalhos (`aliases`) configurados no seu terminal para comeÃ§ar a transcrever seus vÃ­deos em portuguÃªs rapidamente.

## âœ¨ Funcionalidades

* **TranscriÃ§Ã£o de Alta Qualidade:** Utiliza os modelos de ponta da OpenAI para gerar textos precisos a partir de Ã¡udios em portuguÃªs.
  
* **AceleraÃ§Ã£o por GPU:** Detecta e utiliza automaticamente sua GPU NVIDIA (via CUDA) para acelerar o processo de transcriÃ§Ã£o. A imagem base foi construÃ­da especificamente para isso, utilizando `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04`.
  
* **MÃºltiplos Formatos de SaÃ­da:** Salva a transcriÃ§Ã£o em trÃªs formatos Ãºteis no mesmo diretÃ³rio do vÃ­deo:
  

Â  Â  * `.txt`: Texto puro e simples.

Â  Â  * `.srt`: Formato de legenda padrÃ£o, com timestamps, compatÃ­vel com a maioria dos players de vÃ­deo.

Â  Â  * `.vtt`: Formato de legenda moderno, usado em players web (HTML5).

* **Setup Automatizado:** Um script Bash (`setup.sh`) cuida da criaÃ§Ã£o da pasta de vÃ­deos, construÃ§Ã£o da imagem Docker (se necessÃ¡rio) e configuraÃ§Ã£o de aliases para facilitar o uso.
  
* **Modelo PrÃ©-carregado:** O modelo de IA padrÃ£o (`small`) Ã© baixado e "instalado" na imagem Docker durante o build. Isso evita o download na primeira execuÃ§Ã£o do contÃªiner, economizando tempo.
  
* **Logging Detalhado:** O script `setup.sh` gera um arquivo de log (`setup_whisper.log`) com o timestamp de cada aÃ§Ã£o e nÃ­vel de severidade (INFO, ERROR), auxiliando na depuraÃ§Ã£o.
  

## ğŸ“‹ PrÃ©-requisitos

Para utilizar este projeto, vocÃª precisa ter os seguintes softwares instalados em seu sistema operacional:

1. Â **Docker:** A plataforma que orquestra e executa o ambiente do Whisper em um contÃªiner isolado.
  
  * [Guia de InstalaÃ§Ã£o do Docker Engine](https://docs.docker.com/engine/install/)
    

2. Â **Placa de VÃ­deo (GPU) NVIDIA (Altamente Recomendado):** Para obter o mÃ¡ximo de desempenho e acelerar significativamente o processo de transcriÃ§Ã£o, uma GPU NVIDIA compatÃ­vel com CUDA Ã© fortemente recomendada.
  
3. Â **Drivers da NVIDIA e NVIDIA Container Toolkit:** Essenciais para permitir que o Docker acesse e utilize sua GPU.
  
  * [Guia de InstalaÃ§Ã£o do NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)

> âš ï¸ **AtenÃ§Ã£o:** Embora o projeto funcione sem uma GPU NVIDIA, a transcriÃ§Ã£o serÃ¡ processada pela CPU e serÃ¡ **significativamente mais lenta**.

## ğŸš€ Como ComeÃ§ar

Siga estes passos para ter o ambiente pronto e comeÃ§ar a transcrever seus vÃ­deos.

### Estrutura do Projeto

Comece clonando este repositÃ³rio e organizando os arquivos:

1. Â **Clone o RepositÃ³rio:**

        git clone https://github.com/malvesro/transcribe.git
    
        cd transcribe

2. Â **Verifique a Estrutura:**

Â  Â  ApÃ³s clonar, a estrutura do seu diretÃ³rio deve ser semelhante a esta:

        transcribe/
    
        â”œâ”€â”€ Dockerfile          # Para construir a imagem Docker
    
        â”œâ”€â”€ transcribe.py       # Script Python principal de transcriÃ§Ã£o
    
        â”œâ”€â”€ setup.sh            # Script de setup automatizado
    
        â””â”€â”€ README.md           # Este arquivo
    
        â”œâ”€â”€ setup_whisper.log   # Arquivo de log gerado pelo setup.sh (serÃ¡ criado apÃ³s a primeira execuÃ§Ã£o)
    
        â””â”€â”€ videos/             # PASTA DOS SEUS VÃDEOS (serÃ¡ criada pelo setup.sh)
    
            â””â”€â”€ seu_video.mp4   # Exemplo: coloque seus arquivos de vÃ­deo aqui

### Executando o Setup Inicial

Este script automatiza o processo de construÃ§Ã£o da imagem Docker e a configuraÃ§Ã£o dos atalhos (`aliases`) para uso fÃ¡cil.

1. Â **Conceder PermissÃµes de ExecuÃ§Ã£o:**

        chmod +x setup.sh

2. Â **Execute o Setup:**

    ./setup.sh

Â  Â  O script `setup.sh` irÃ¡:

Â  Â  * Verificar a instalaÃ§Ã£o e status do Docker.

Â  Â  * Criar a pasta `videos/` se ela nÃ£o existir.

Â  Â  * Construir a imagem Docker (`whisper-transcriber`) com o modelo `small` prÃ©-carregado (se a imagem ainda nÃ£o existir).

Â  Â  * Definir dois aliases de terminal (`transcribe` e `transcribegpu`) para a sua sessÃ£o atual.

Â  Â  * Gerar um arquivo de log detalhado (`setup_whisper.log`) com todas as aÃ§Ãµes.

Â  Â  * Exibir um guia de uso rÃ¡pido no final.

## âš¡ Uso da Ferramenta

ApÃ³s a execuÃ§Ã£o bem-sucedida do `setup.sh`, vocÃª pode usar os aliases `transcribe` ou `transcribegpu` diretamente no seu terminal (na mesma sessÃ£o).

**Lembre-se:** Coloque os arquivos de vÃ­deo que deseja transcrever dentro da pasta `videos/`.

### Exemplos de TranscriÃ§Ã£o para VÃ­deos em PortuguÃªs

O script `transcribe.py` Ã© configurado para transcrever para o **PortuguÃªs** por padrÃ£o (`language="pt"`).

**Exemplo 1: TranscriÃ§Ã£o RÃ¡pida com Modelo PadrÃ£o (via CPU)**

Ideal se vocÃª nÃ£o tem GPU NVIDIA ou prefere um processamento mais leve. O modelo `small` Ã© utilizado por padrÃ£o.

    
    transcribe --video "minha_reuniao_da_empresa.mp4"
    

* Resultado: Os arquivos minha_reuniao_da_empresa.txt, minha_reuniao_da_empresa.srt e minha_reuniao_da_empresa.vtt serÃ£o salvos na sua pasta videos/.

Exemplo 2: TranscriÃ§Ã£o de Alta Qualidade (via GPU)

Para aproveitar sua placa de vÃ­deo NVIDIA e obter maior velocidade, ou para usar modelos maiores e mais precisos.

    
    transcribegpu --video "palestra_tecnica.mp4" --model "medium"
    

* Resultado: Os arquivos de transcriÃ§Ã£o (.txt, .srt, .vtt) serÃ£o gerados na sua pasta videos/.

### Entendendo os Aliases (`transcribe` e `transcribegpu`)

Estes aliases encapsulam os comandos `docker run` para simplificar a execuÃ§Ã£o:

* **`transcribe`:** `docker run --rm -v "$(pwd)/videos":/data whisper-transcriber`
  * `--rm`: Remove o contÃªiner apÃ³s a execuÃ§Ã£o.
  * `-v "$(pwd)/videos":/data`: Monta a pasta local `videos/` (onde estÃ£o seus vÃ­deos) no diretÃ³rio `/data` dentro do contÃªiner. O script `transcribe.py` acessa os vÃ­deos e salva os resultados em `/data`.
  * `whisper-transcriber`: O nome da imagem Docker construÃ­da.
* **`transcribegpu`:** `docker run --rm --gpus all -v "$(pwd)/videos":/data whisper-transcriber`
  * `--gpus all`: Permite que o contÃªiner acesse **todas** as GPUs NVIDIA disponÃ­veis no seu sistema, maximizando a aceleraÃ§Ã£o.

### Uso AvanÃ§ado: Trocando o Modelo

Por padrÃ£o, o `transcribe.py` utiliza o modelo `small` do Whisper. VocÃª pode especificar um modelo diferente usando a flag `--model`:

**Modelos DisponÃ­veis:** `tiny`, `base`, `small`, `medium`, `large`, `large-v2`, `large-v3`.

* **Modelos menores (`tiny`, `base`):** SÃ£o mais rÃ¡pidos, consomem menos memÃ³ria, mas oferecem menor precisÃ£o na transcriÃ§Ã£o.
* **Modelos maiores (`medium`, `large`, `large-v2`, `large-v3`):** SÃ£o mais lentos e exigem mais memÃ³ria (especialmente uma GPU com mais VRAM), mas proporcionam a maior precisÃ£o.

**Para ver todos os argumentos e opÃ§Ãµes disponÃ­veis no script de transcriÃ§Ã£o, execute:**

    transcribe --help

**AtenÃ§Ã£o:** Os aliases criados pelo `setup.sh` sÃ£o **temporÃ¡rios** e vÃ¡lidos apenas para a sessÃ£o atual do seu terminal. Para tornÃ¡-los **permanentes**, adicione as seguintes linhas ao final do seu arquivo de configuraÃ§Ã£o do shell (e.g., `~/.bashrc` ou `~/.zshrc`), e recarregue-o com `source`:

    alias transcribe='docker run --rm -v "$(pwd)/videos:/data" whisper-transcriber'
    alias transcribegpu='docker run --rm --gpus all -v "$(pwd)/videos:/data" whisper-transcriber'

Depois, execute: `source ~/.bashrc` (ou `source ~/.zshrc`).âš™ï¸ Detalhes TÃ©cnicos

* * *

Esta seÃ§Ã£o detalha o propÃ³sito de cada arquivo principal do projeto.

### `Dockerfile.txt`

Este arquivo Ã© a "receita" para construir a imagem Docker do Whisper Transcriber. Ele define o ambiente operacional e as dependÃªncias necessÃ¡rias.

* **Imagem Base:** Inicia a construÃ§Ã£o a partir de `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04`, uma imagem que jÃ¡ contÃ©m Ubuntu 22.04, CUDA 12.1.1 e cuDNN 8, essenciais para o suporte a GPU. A tag `devel` garante que compiladores e headers para CUDA estejam presentes.
* **DependÃªncias do Sistema:** Instala `python3.10`, `python3-pip`, `ffmpeg` (crucial para lidar com formatos de Ã¡udio/vÃ­deo) e `git` via `apt-get`. Limpa o cache para otimizar o tamanho da imagem.
* **DependÃªncias Python:** Instala `torch` com suporte a CUDA 12.1 e a Ãºltima versÃ£o do `openai-whisper` via `pip3`.
* **PrÃ©-carregamento do Modelo:** Executa um comando Python durante o build para baixar e cachear o modelo `small` do Whisper. Isso economiza tempo na primeira execuÃ§Ã£o do contÃªiner, pois o modelo jÃ¡ estarÃ¡ disponÃ­vel em `/root/.cache/whisper/` dentro da imagem.
* **Estrutura do ContÃªiner:** Define `/app` como diretÃ³rio de trabalho inicial, copia `transcribe.py` para lÃ¡. Posteriormente, define `/data` como o `WORKDIR` final, que serÃ¡ o ponto de montagem para seus vÃ­deos.
* **Ponto de Entrada:** Configura `ENTRYPOINT ["python3", "/app/transcribe.py"]`. Isso significa que, ao executar o contÃªiner, o script `transcribe.py` serÃ¡ automaticamente chamado, e quaisquer argumentos adicionais passados ao `docker run` serÃ£o enviados diretamente para ele.

### `transcribe.py`

Este Ã© o script Python principal que executa a lÃ³gica de transcriÃ§Ã£o.

* **Parsing de Argumentos:** Utiliza `argparse` para processar os argumentos da linha de comando, como `--video` (obrigatÃ³rio) e `--model` (opcional, padrÃ£o `small`).
* **VerificaÃ§Ã£o de GPU:** Verifica a disponibilidade de CUDA com `torch.cuda.is_available()`. Imprime uma mensagem informativa sobre a GPU detectada ou um aviso se CUDA nÃ£o estiver disponÃ­vel, indicando que a transcriÃ§Ã£o serÃ¡ mais lenta.
* **Carregamento e TranscriÃ§Ã£o:** Carrega o modelo Whisper especificado e, em seguida, chama `model.transcribe()` para processar o vÃ­deo, definindo o idioma para portuguÃªs (`language="pt"`) e habilitando `fp16` para otimizaÃ§Ã£o em GPU.
* **Salvamento de SaÃ­da:** ApÃ³s a transcriÃ§Ã£o, o texto completo Ã© impresso no terminal e a funÃ§Ã£o `save_transcription()` Ã© chamada. Esta funÃ§Ã£o utiliza `whisper.utils.get_writer` para salvar os resultados nos formatos `.txt`, `.srt` e `.vtt` no mesmo diretÃ³rio de onde o vÃ­deo foi carregado.

### `setup.sh`

Este Ã© um script de conveniÃªncia em Bash que automatiza a configuraÃ§Ã£o inicial do ambiente.

* **LÃ³gica Principal:** Gerencia a verificaÃ§Ã£o do Docker, criaÃ§Ã£o de diretÃ³rios, construÃ§Ã£o condicional da imagem Docker e configuraÃ§Ã£o de aliases de forma amigÃ¡vel ao usuÃ¡rio.
* **Melhores PrÃ¡ticas:** Inclui tratamento de erros (`set -e`, `trap`), logging detalhado para arquivo (`setup_whisper.log`) e mensagens coloridas no terminal para uma melhor experiÃªncia do usuÃ¡rio.
* **IdempotÃªncia:** Verifica a existÃªncia da imagem Docker e da pasta `videos/` antes de tentar criÃ¡-las, tornando-o seguro para execuÃ§Ãµes repetidas.

ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o muito bem-vindas! Se vocÃª tiver ideias para melhorias, encontrar bugs ou quiser adicionar novas funcionalidades, sinta-se Ã  vontade para:

1. Fazer um "fork" do projeto.
2. Criar uma nova "branch" (`git checkout -b feature/sua-feature`).
3. Implementar suas mudanÃ§as.
4. Fazer um "commit" com mensagens claras (`git commit -m 'feat: Adiciona nova funcionalidade X'`).
5. Enviar suas mudanÃ§as (`git push origin feature/sua-feature`).
6. Abrir um "Pull Request" (PR) no repositÃ³rio principal.

ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Para mais detalhes, consulte o arquivo `LICENSE` no repositÃ³rio.âœ‰ï¸ Contato

* * *

Para dÃºvidas, sugestÃµes ou suporte, vocÃª pode abrir uma "Issue" neste repositÃ³rio GitHub: [https://github.com/malvesro/transcribe/issues](https://www.google.com/search?q=https://github.com/malvesro/transcribe/issues)